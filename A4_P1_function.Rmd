---
title: "A4_P1_function"
author: "JK"
date: "8 listopadu 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(pacman)
p_load(tidyverse,
       gridExtra, #grid.arrange()
       crqa, #crqa()
       lmerTest,
       doParallel, #parallel processing
       groupdata2) #downsampling

# parallel processing
cl <- makeCluster(detectCores(), type='PSOCK')
registerDoParallel(cl)
```


## data loado
```{r data loading}
files <- list.files(path = "data/", pattern="*.csv", full.names = T)

read_heart <- function(filename) {
    raw <- read_csv(filename,
                    col_types = list(time = col_double(),
                                     Resp1 = col_double(),
                                     Resp2 = col_double(),
                                     ECG1 = col_double(),
                                     ECG2 = col_double(),
                                     ReadingStart = col_integer(),
                                     ReadingStop = col_integer(),
                                     HR1 = col_double(),
                                     HR2 = col_double()))
    name <- as.character(filename)
    
    data <- cbind(raw, name) %>%
      mutate(nrow = nrow(raw)) #%>%
      #summarise()
    
    data <- data %>%
      mutate(name = str_remove_all(name, "data/"),
         name = str_remove_all(name, ".csv")) %>%
      
      mutate(study = substr(name, 6, 6),
         group = substr(name, 9, 10),
         group = str_remove_all(group, "_"),
         t = substr(name, 12, 13),
         t = str_remove_all(t, "_"),
         t = str_remove_all(t, "T"),
         condition = substr(name, 14, 30),
         condition = str_remove_all(condition, "_")) %>%
      
      select(-name)
    
    return(data)
}

all <- map_df(files, read_heart) %>%
  filter(study == "3") %>%
  mutate(t = factor(t),
         condition = factor(condition),
         ReadingStart = as.numeric(ReadingStart),
         ReadingStop = as.numeric(ReadingStop),
         nrow = as.numeric(nrow),
         study = factor(study),
         group = factor(group)) %>%
  rownames_to_column()
```


## data preprocesso
```{r preprocessing}
idiot1_idiot2_analysis <- function(data, threshold) {
  
  ## DOWNSAMPLING
  
  # summarise
  d1 <- data %>%
    group(n = 100, method = 'greedy') %>%
    dplyr::summarise(
      time = mean(time,na.rm=T),
      HR1 = mean(HR1,na.rm=T),
      HR2 = mean(HR2,na.rm=T),
      Resp1 = mean(Resp1,na.rm=T),
      Resp2 = mean(Resp2,na.rm=T),
      rowname = rowname[1]) #the index we use to put them back together 
  
  # collect
  d2 <- left_join(d1, data, by = "rowname") %>%
    select(-matches("\\.y"))
  
  
  
  ## OUTLIERS
  # funciton
  removeOuts <- function(ts,threshold){
    ts[ts > (mean(ts,na.rm=T) +
               (threshold*sd(ts,na.rm=T))) | 
         ts < (mean(ts,na.rm=T) -
                 (threshold*sd(ts,na.rm=T)))] = mean(ts,na.rm=T)
    return(ts)
  }
  
  # set threshold
  threshold=threshold
  
  # do the job
  d3 <- d2 %>%
    group_by(group, condition) %>%
    mutate(hr1  = removeOuts(HR1.x, threshold),
           hr2  = removeOuts(HR2.x, threshold),
           ecg1 = removeOuts(ECG1, threshold),
           ecg2 = removeOuts(ECG2, threshold),
           resp1 = removeOuts(Resp1.x, threshold),
           resp2 = removeOuts(Resp2.x, threshold))
  
  
  
  ## SCALING
  
  # function
  z_scale <- function(column){
    column_c <- (column - mean(column)) / sd(column)
  }
  
  # do the job
  d4 <- d3 %>%
    group_by(condition, group) %>%
    mutate(resp1S = z_scale(resp1),
           resp2S = z_scale(resp2),
           hr1S = z_scale(hr1),
           hr2S = z_scale(hr2),
           ecg1S = z_scale(ecg1),
           ecg2S = z_scale(ecg2))
  
  
  ## OUTPUT
  return(d4)
  
}

d4 <- idiot1_idiot2_analysis(all, threshold = 2.5)
rm(all)
```


## data plotto
```{r plotting}
plotty <- function(data, group_nr){
  c1 <- data %>%
    filter(group == group_nr) %>%
    ggplot() +
    geom_line(aes(as.numeric(TimeMs), hr1S, color = "P1")) +
    geom_line(aes(as.numeric(TimeMs), hr2S, color = "P2")) +
    labs(x = "time in 100 ms", y = "HR") +
    theme(legend.position="bottom")
  
  # scaled RESP
  c2 <- data %>%
    filter(group == group_nr) %>%
    ggplot() +
    geom_line(aes(as.numeric(TimeMs), resp1S, color = "P1")) +
    geom_line(aes(as.numeric(TimeMs), resp2S, color = "P2")) +
    labs(x = "time in 100 ms", y = "RESP") +
    theme(legend.position="bottom")
  
  # scaled ECG
  c3 <- data %>% 
    filter(group == group_nr) %>%
    ggplot() +
    geom_line(aes(as.numeric(TimeMs), ecg1S, color = "P1")) +
    geom_line(aes(as.numeric(TimeMs), ecg2S, color = "P2")) +
    labs(x = "time in 100 ms", y = "ECG") +
    theme(legend.position="bottom")
  
  ## colected
  grid.arrange(c1, c2, c3, ncol=3, top = "Plots of physiological data (HR, RESP, ECG) with downsampling, outlier removal & scaling", 
               bottom = paste0("Group ", group_nr))
  
}

plotty(d4, group_nr = "10")
```


## setting up optimizeParam()
```{r optimize setup}
## set parameters
par = list(lgM = 50, 
           steps = seq(1, 6, 1), 
           radiusspan = 100,
           radiussample = 40, 
           normalize = 0, 
           rescale = 0, #slide code = 0
           mindiagline = 2,
           minvertline = 2, 
           tw = 0, 
           whiteline = FALSE, 
           recpt = FALSE, 
           fnnpercent = 10, 
           typeami = "mindip")



## version of optimizeParam that returnt an error message if something goes wrong
# agruments: timeseries and parameters for optimizeParam() function

non_picky_optimizeParam <- function(TS1, TS2, parameters) {
  
  return(
    # try running the expression using specified arugments
    tryCatch(expr = (optimizeParam(TS1, TS2, parameters, min.rec = 2, max.rec = 5)),
             # when error / warning occurs, it saves the message as character
           error=function(e) as.character(e), warning=function(w) as.character(w))
    )
}



## THE FUNCTION
optimizeAlot <- function(df, group_nr, parameter_list) {
  
  # one group only
  data <- df %>%
    dplyr::filter(group == as.character(group_nr))
  
  # split into 3 conditions
  data_synch <- data %>%
    dplyr::filter(condition == "Synchronous")
  
  data_conv <- data %>%
    dplyr::filter(condition == "Conversation")
  
  data_turn <- data %>%
    dplyr::filter(condition == "TurnTaking")
  
  
  ## optimize
  Synchronous_HR <- non_picky_optimizeParam(data_synch$hr1S, data_synch$hr2S, 
                                            parameters = parameter_list)
  Synchronous_RESP <- non_picky_optimizeParam(data_synch$resp1S, data_synch$resp2S, 
                                              parameters = parameter_list)
  Synchronous_ECG <- non_picky_optimizeParam(data_synch$ecg1S, data_synch$ecg2S, 
                                             parameters = parameter_list)
  
  Conversation_HR <- non_picky_optimizeParam(data_conv$hr1S, data_conv$hr2S, 
                                             parameters = parameter_list)
  Conversation_RESP <- non_picky_optimizeParam(data_conv$resp1S, data_conv$resp2S, 
                                               parameters = parameter_list)
  Conversation_ECG <- non_picky_optimizeParam(data_conv$ecg1S, data_conv$ecg2S, 
                                              parameters = parameter_list)
  
  TurnTaking_HR <- non_picky_optimizeParam(data_turn$hr1S, data_turn$hr2S, 
                                           parameters = parameter_list)
  TurnTaking_RESP <- non_picky_optimizeParam(data_turn$resp1S, data_turn$resp2S,
                                             parameters = parameter_list)
  TurnTaking_ECG <- non_picky_optimizeParam(data_turn$ecg1S, data_turn$ecg2S,
                                            parameters = parameter_list)
  
  
  ## data
  bind <- rbind.data.frame("Synchronous_HR" = Synchronous_HR,
                           "Synchronous_RESP" = Synchronous_RESP,
                           "Synchronous_ECG" = Synchronous_ECG,
                           "Conversation_HR" = Conversation_HR,
                           "Conversation_RESP" = Conversation_RESP,
                           "Conversation_ECG" = Conversation_ECG,
                           "TurnTaking_HR" = TurnTaking_HR,
                           "TurnTaking_RESP" = TurnTaking_RESP,
                           "TurnTaking_ECG" = TurnTaking_ECG) %>%
    cbind.data.frame('group' = group_nr) %>%
    rownames_to_column() %>%
    separate(rowname, c("Condition", "Metric"), "_")
  
  
  ## return
  return(bind)
  
}
```

## running optimisation
watch out! Takes almost 8 minutes to run
```{r optimize run}
set.seed(666)
all_groups <- c(1, 2, 4:10)

start = Sys.time()
optimal_para <- map_df(all_groups, 
                       optimizeAlot, 
                       df = d4,
                       parameter_list = par)
stop = Sys.time()

stop - start
```


## median parameters
```{r}
med_optimal_para <- optimal_para %>%
  mutate(delay = as.numeric(delay),
         emddim = as.numeric(emddim),
         radius = as.numeric(radius)) %>%
  
  group_by(Metric, Condition) %>%
  
  summarise(delay = median(delay, na.rm = T),
            emddim = median(emddim, na.rm = T),
            radius = median(radius, na.rm = T))
```


## CRQA
```{r crqa function}
# CRQA LOOP
crqa_hell <- function(df, group_nr, var1, var2) {
  
  data <- df %>%
    dplyr::filter(group == as.character(group_nr))
  
  crqa_list = c()
  
  for (i in 1:9) {
    
    crqa_list[i] <- list(crqa(ts1 = data[[var1]], 
                              ts2 = data[[var2]], 
                              delay = as.numeric(med_optimal_para[i, 3]), #delay 
                              embed = as.numeric(med_optimal_para[i, 4]), #emdim 
                              radius = as.numeric(med_optimal_para[i, 5]), #radius
                              normalize=0,
                              rescale=0,
                              mindiagline =2,
                              minvertline = 2))
    
    i = i + 1
  }
  
  # list into matrix
  crqa_matrix <- do.call("rbind", crqa_list)
  
  # metrics, conditions, group nr
  metrics_conditions <- as.matrix(med_optimal_para[,1:2])
  group_nr_matrix <- as.matrix(rep(group_nr, times = 9))
    
  # merging
  crqa_matrix_informative <- cbind(crqa_matrix, metrics_conditions)
  crqa_matrix_informative_2 <- cbind(crqa_matrix_informative, group_nr_matrix)
  
  # return
  return(crqa_matrix_informative_2)
}

make_crqa_DF <- function(input) {
  
  crqa_big_matrix <- do.call("rbind", input)
  
  crqa_df <- as.data.frame(crqa_big_matrix[,-10])
  crqa_df <- as.data.frame(sapply(crqa_df, unlist), stringsAsFactors = F) 
  
  return(crqa_df)
}

make_crqa_RP <- function(input) {
  
  crqa_big_matrix <- do.call("rbind", input)
  crqa_rp <- as.matrix(crqa_big_matrix[,10:13])
  
  return(crqa_rp)
}

```

```{r crqa run}
set.seed(666)
start = Sys.time()

# loop trough all groups
crqa_resp <- lapply(all_groups, 
                       crqa_hell, 
                       df = d4,
                    var1 = "resp1S",
                    var2 = "resp2S")

crqa_hr <- lapply(all_groups, 
                       crqa_hell, 
                       df = d4,
                  var1 = "hr1S",
                  var2 = "hr2S")

crqa_ecg <- lapply(all_groups, 
                       crqa_hell, 
                       df = d4,
                   var1 = "ecg1S",
                   var2 = "ecg2S")

# wrangling
crqa_resp_df <- make_crqa_DF(crqa_resp)
crqa_hr_df <- make_crqa_DF(crqa_hr)
crqa_ecg_df <- make_crqa_DF(crqa_ecg)

crqa_resp_rp <- make_crqa_RP(crqa_resp)
crqa_hr_rp <- make_crqa_RP(crqa_hr)
crqa_ecg_rp <- make_crqa_RP(crqa_ecg)


# benchmark
stop = Sys.time()
stop - start


# fix column type
# write_csv(crqa_df, "crqa_df.csv")
crqa_df <- read_csv("crqa_df.csv") %>%
  rename(Group = V12)
```


## later gator
```{r}
RP=results_test$RP
RP = matrix(as.numeric(RP), nrow = ncol(RP))
cols = c("white", "blue4")
image(RP, xlab = "", ylab = "", col = cols)

Profile=drpdfromts(test$resp1S, test$resp2S,datatype = 'continuous',ws=50,radius=1.68739078850316)
timecourse = round( seq(-5000,5000,100)/1000, digit = 1)
mindip = Profile$mindip/1000
profile = Profile$profile*100
Prof=data.frame(profile)
ggplot(Prof, aes(timecourse,profile))+geom_line()+ geom_vline(xintercept = timecourse[mindip], colour='red')
```

## scrambling time-series
rearange in a random order
```{r}
set.seed(666)
d4_shuffle <- d4 %>% mutate(
    hr1S = sample(hr1S),
    hr2S = sample(hr2S),
    resp1S = sample(resp1S),
    resp2S = sample(resp2S),
    ecg1S = sample(ecg1S),
    ecg2S = sample(ecg2S)
)
```


## surrogate paths / controls
Malte will explain later
```{r}
set.seed(666)
expand <- expand.grid(person1s = seq(5,10,1), person2s = seq(5,10,1)) %>%
  filter(person1s != person2s)
```


## Anders monday

```{r}
surrogate_list = c()
for (i in 1:30) {
    surrogate_list[i] <- list(d4 %>% filter(group == expand[i,1]))
    part_2 <- d4 %>% filter(group == expand[i,2])
    
    surrogate_list[[i]] = surrogate_list[[i]][1:7200, ]
    
    surrogate_list[[i]]$hr2S = part_2$hr2S[1:7200]
    surrogate_list[[i]]$resp2S = part_2$resp2S[1:7200]
    surrogate_list[[i]]$ecg2S = part_2$ecg2S[1:7200]
    
    surrogate_list[[i]]$group = i

    i = i + 1
}

surrogate_df <- do.call("rbind", surrogate_list)
```


# MODELING
to include: RR
```{r scaling}
# new df not to overwrite
crqa_scaled <- crqa_df

# MINMAX
for (i in c(1:9)) {
  minc = min(crqa_scaled[,i])
  maxc = max(crqa_scaled[,i])
  crqa_scaled[,i] = (crqa_scaled[,i]-minc)/(maxc-minc)
}

# keep it clean
rm(i, maxc, minc)
```

```{r first modeling}
m1 <- lmer(RR ~ . + (1|Group), data = crqa_scaled)
```



## cross-validation?

```{r cross-validation preparation}
set.seed(1337)
# adds a new column with fold number
crqa_scaled <- fold(crqa_scaled, k = 5, 
             cat_col = 'diagnosis', #balances ratio between shizo/control
             id_col = 'ID') #keeps same people in same folds

crossvalidation_nation <- function(data, k, model_name, dependent, pos, neg) {
  # Initialize empty list for recording performances
  performances_SEN <- c()
  performances_SPE <- c()
  performances_PPV <- c()
  performances_NPV <- c()
  performances_AUC <- c()
  performances_ACC <- c()

  
    # One iteration per fold
  for (fold in 1:k){   #from 1 to k
    
    # Create training set for this iteration
    # Subset all the datapoints where .folds does not match the current fold
    training_set <- data[data$.folds != fold,]
    
    # Create test set for this iteration
    # Subset all the datapoints where .folds matches the current fold
    testing_set <- data[data$.folds == fold,]
    
    ## Train model

    # If there is a random effect,
    # use lmer() to train model
    # else use lm()

    model <- glmer(model_name, training_set, family = "binomial")
    

    ## Test model

    # Predict the dependent variable in the testing_set with the trained model
    predicted <- inv.logit(predict(model, testing_set, allow.new.levels=TRUE))
    
    # Make predicted into factors
    predicted[predicted < 0.5] = "0"
    predicted[predicted >= 0.5] = "1"
    predicted <- factor(predicted)
    
    # Get model performance metrics between the predicted and the observed
    SEN <- caret::sensitivity(predicted, testing_set[[dependent]], positive = pos)
    
    SPE <- caret::specificity(predicted, testing_set[[dependent]], negative = neg)
    
    PPV <- posPredValue(predicted, testing_set[[dependent]], positive = pos)
    
    NPV <- negPredValue(predicted, testing_set[[dependent]], negative = neg)
    
    predicted <- as.numeric(predicted)
    rocCurve <- roc(response = testing_set$diagnosis, predictor = predicted)
    AUC <- pROC::auc(rocCurve)
    
    testing_set$predicted <- predicted
    testing_correct <- filter(testing_set, diagnosis == predicted)
    ACC <- nrow(testing_correct) / nrow(testing_set)
    
    # Add the to the performance list
    performances_SEN[fold] <- SEN
    performances_SPE[fold] <- SPE
    performances_PPV[fold] <- PPV
    performances_NPV[fold] <- NPV
    performances_AUC[fold] <- AUC
    performances_ACC[fold] <- ACC

  }

  # Return the mean of the recorded RMSEs
  return(cbind.data.frame('model' = model_name,
           'SEN' = mean(performances_SEN, na.rm = T),
           'SPE' = mean(performances_SPE, na.rm = T),
           'PPV' = mean(performances_PPV, na.rm = T),
           'NPV' = mean(performances_NPV, na.rm = T),
           'AUC' = mean(performances_AUC, na.rm = T),
           'ACC' = mean(performances_ACC, na.rm = T)))

}
```

```{r cross run}
m1 <- "diagnosis ~ range + Gender + (1|uniqueness) + (1|study)"
m2 <- "diagnosis ~ sd + Gender + (1|uniqueness) + (1|study)"
m3 <- "diagnosis ~ mean + Gender + (1|uniqueness) + (1|study)"
m4 <- "diagnosis ~ median + Gender + (1|uniqueness) + (1|study)"
m5 <- "diagnosis ~ iqr + Gender + (1|uniqueness) + (1|study)"
m6 <- "diagnosis ~ mean_abs + Gender + (1|uniqueness) + (1|study)"
m7 <- "diagnosis ~ coef_var + Gender + (1|uniqueness) + (1|study)"

model_list <- list(m1, m2, m3, m4, m5, m6, m7)

#

set.seed(1337)
cross_table <- map_df(
            #list to loop trough
            model_list,
            #function to use
            crossvalidation_nation,
            # arguments
            data = Bear_scaled, 
            k = 5,
            dependent = "diagnosis", 
            pos = "1", 
            neg = "0")
```

